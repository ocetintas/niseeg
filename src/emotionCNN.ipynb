{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "emotionCNN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sQpka0B6YF_H",
        "outputId": "a471eedd-c915-4d57-821e-04db9527036b"
      },
      "source": [
        "#! pip install keras==2.2.4\n",
        "\n",
        "#! pip install innvestigate\n",
        "%tensorflow_version 1.x\n",
        "import keras\n",
        "import keras.backend\n",
        "import keras.layers\n",
        "import keras.models\n",
        "import keras.utils\n",
        "import torch\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "import sys\n",
        "import glob\n",
        "import pickle\n",
        "import scipy.io\n",
        "import os\n",
        "drive.mount(\"/content/drive/\")\n",
        "sys.path.append('/content/drive/My Drive/')\n",
        "\n",
        "import innvestigate\n",
        "import innvestigate.utils as iutils\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fUbCdEb-YSW9"
      },
      "source": [
        "class DEAP:\n",
        "    def __init__(\n",
        "        self, subject=12, num_segments=12, device=\"cpu\", num_classes=3, upsample=True\n",
        "    ):\n",
        "        self.subject = subject\n",
        "        self.num_segments = num_segments\n",
        "        self.device = device\n",
        "        self.num_classes = num_classes\n",
        "        self.upsample = upsample\n",
        "        self._load_data()\n",
        "\n",
        "    def _get_subject_file_names(self, s):\n",
        "        eeg_root_folder = \"/content/drive/My Drive/data_preprocessed_matlab\"\n",
        "        landmarks_root_folder = \"/content/drive/My Drive/landmarks\"\n",
        "        subject_code = \"s\" + \"{:02d}\".format(s)\n",
        "        # Get eeg file name\n",
        "        eeg_file = os.path.join(eeg_root_folder, subject_code + \".mat\")\n",
        "        # Get the landmark file names\n",
        "        landmark_files = []\n",
        "        for t in range(1, 41):\n",
        "            trial_code = \"trial\" + \"{:02d}\".format(t)\n",
        "            trial_file_name = os.path.join(\n",
        "                landmarks_root_folder,\n",
        "                subject_code,\n",
        "                subject_code + \"_\" + trial_code + \".npy\",\n",
        "            )\n",
        "            landmark_files.append(trial_file_name)\n",
        "        return eeg_file, landmark_files\n",
        "\n",
        "    def _read_eeg_file(self, file, seconds_to_remove=3, sampling_freq=128):\n",
        "        data = scipy.io.loadmat(file)\n",
        "        eeg_data = data[\"data\"][\n",
        "            :, :32, :\n",
        "        ]  # First 32 channels belong to the EEG (video=40, channel=40, data=8064)\n",
        "        eeg_data = eeg_data[\n",
        "            :, :, sampling_freq * seconds_to_remove :\n",
        "        ]  # Remove baseline recording\n",
        "        labels = (\n",
        "            data[\"labels\"] // 3.3\n",
        "        )  # valence, arousal, dominance, liking (video=40, 4)\n",
        "        assert eeg_data.shape == (\n",
        "            40,\n",
        "            32,\n",
        "            8064 - sampling_freq * seconds_to_remove,\n",
        "        ), \"EEG data reading failed!\"\n",
        "        assert labels.shape == (40, 4), \"Labels reading failed!\"\n",
        "        return eeg_data, labels\n",
        "\n",
        "    def _read_landmark_files(self, files):\n",
        "        landmark_data = []\n",
        "        for f in files:\n",
        "            trial_data = np.load(f)\n",
        "            trial_data = np.reshape(\n",
        "                trial_data, (trial_data.shape[0], -1)\n",
        "            )  # (3000, 81*2)\n",
        "            trial_data = np.transpose(trial_data)  # (81*2, 3000)\n",
        "            landmark_data.append(trial_data)\n",
        "        landmark_data = np.array(\n",
        "            landmark_data\n",
        "        )  # (video=40, 81*2, 3000) Compatible with EEG\n",
        "        assert landmark_data.shape == (\n",
        "            40,\n",
        "            81 * 2,\n",
        "            3000,\n",
        "        ), \"Landmark data reading failed!\"\n",
        "        return landmark_data\n",
        "\n",
        "    def _epoch_data(self, eeg_data, labels, landmark_data):\n",
        "        assert (\n",
        "            eeg_data.shape[0] == landmark_data.shape[0]\n",
        "        ), \"Mismatch between EEG and landmark data\"\n",
        "        assert (\n",
        "            eeg_data.shape[2] % self.num_segments == 0\n",
        "            and landmark_data.shape[2] % self.num_segments == 0\n",
        "        ), \"Choose a better number of segments\"\n",
        "        eeg_data_per_segment = int(eeg_data.shape[2] / self.num_segments)\n",
        "        landmark_data_per_segment = int(landmark_data.shape[2] / self.num_segments)\n",
        "\n",
        "        eeg, landmark = [], []\n",
        "        for v in range(eeg_data.shape[0]):\n",
        "            for i in range(self.num_segments):\n",
        "                eeg.append(\n",
        "                    eeg_data[\n",
        "                        v, :, i * eeg_data_per_segment : (i + 1) * eeg_data_per_segment\n",
        "                    ]\n",
        "                )\n",
        "                landmark.append(\n",
        "                    landmark_data[\n",
        "                        v,\n",
        "                        :,\n",
        "                        i\n",
        "                        * landmark_data_per_segment : (i + 1)\n",
        "                        * landmark_data_per_segment,\n",
        "                    ]\n",
        "                )\n",
        "\n",
        "        self.eeg = np.array(eeg).transpose(0, 2, 1)  # (batch, seq, feature)\n",
        "        self.landmark = np.array(landmark).transpose(0, 2, 1)  # (batch, seq, feature)\n",
        "        self.labels = np.repeat(\n",
        "            labels, self.num_segments, axis=0\n",
        "        )  # (batch, 4 emotions)\n",
        "\n",
        "        assert self.eeg.shape == (\n",
        "            eeg_data.shape[0] * self.num_segments,\n",
        "            eeg_data_per_segment,\n",
        "            eeg_data.shape[1],\n",
        "        ), \"EEG epoching went wrong!\"\n",
        "        assert self.landmark.shape == (\n",
        "            landmark_data.shape[0] * self.num_segments,\n",
        "            landmark_data_per_segment,\n",
        "            landmark_data.shape[1],\n",
        "        ), \"Landmark epoching went wrong\"\n",
        "        assert self.labels.shape == (\n",
        "            labels.shape[0] * self.num_segments,\n",
        "            4,\n",
        "        ), \"Label epoching went wrong\"\n",
        "        assert (\n",
        "            self.eeg.shape[0] == self.landmark.shape[0]\n",
        "            and self.landmark.shape[0] == self.labels.shape[0]\n",
        "        ), \"Number of data does not match!\"\n",
        "\n",
        "    def _load_data(self):\n",
        "        eeg_file, landmark_files = self._get_subject_file_names(self.subject)\n",
        "        eeg_data, labels = self._read_eeg_file(eeg_file)\n",
        "        landmark_data = self._read_landmark_files(landmark_files)\n",
        "        self._epoch_data(eeg_data, labels, landmark_data)\n",
        "        if self.upsample:\n",
        "            self._upsample_landmarks()\n",
        "        self._normalize_landmarks()\n",
        "        self._normalize_eeg()\n",
        "\n",
        "    def _normalize_landmarks(self):\n",
        "        mean = np.mean(self.landmark)\n",
        "        std = np.std(self.landmark)\n",
        "        self.landmark = (self.landmark - mean) / std\n",
        "\n",
        "    def _normalize_eeg(self):\n",
        "        mean = np.mean(self.eeg)\n",
        "        std = np.std(self.eeg)\n",
        "        self.eeg = (self.eeg - mean) / std\n",
        "\n",
        "    def _upsample_landmarks(self):\n",
        "        \"\"\"\n",
        "        Match the dimensions of landmarks and eeg data by linear upsampling\n",
        "        \"\"\"\n",
        "        upsampler = torch.nn.Upsample(\n",
        "            scale_factor=2.56, mode=\"linear\", align_corners=False\n",
        "        )\n",
        "        self.landmark = upsampler(\n",
        "            torch.from_numpy(self.landmark).permute(0, 2, 1)\n",
        "        ).permute(\n",
        "            0, 2, 1\n",
        "        )  # batch, seq, feature\n",
        "        self.landmark = self.landmark.numpy()\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.eeg.shape[0]\n",
        "\n",
        "    def __getitem__(self, ix):\n",
        "        return {\n",
        "            \"eeg\": self.eeg[ix],\n",
        "            \"face\": self.landmark[ix],\n",
        "            \"label_val\": keras.utils.to_categorical(\n",
        "                self.labels[ix, 0], num_classes=self.num_classes\n",
        "            ),\n",
        "            \"label_arousal\": keras.utils.to_categorical(\n",
        "                self.labels[ix, 1], num_classes=self.num_classes\n",
        "            ),\n",
        "        }\n",
        "\n",
        "    def train_valid_split(self, split_ratio=0.2):\n",
        "        split_idx = int(split_ratio * len(self))\n",
        "        indices = np.arange(len(self))\n",
        "        np.random.shuffle(indices)\n",
        "        train_indices, val_indices = indices[split_idx:], indices[:split_idx]\n",
        "        return train_indices, val_indices"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-JMWmpw1YG6H"
      },
      "source": [
        "## Model collection\n",
        "from innvestigate.utils.tests.networks import base as network_base\n",
        "from keras.models import Model\n",
        "\n",
        "def build_two_heads_net(input_shape_eeg=(None,1, 640, 32), input_shape_fl=(None, 1, 250, 81*2), output_n_eeg=8, output_n_fl=8, output_n=3):\n",
        "    net = {}\n",
        "    net[\"eeg_in\"] = network_base.input_layer(shape=input_shape_eeg)\n",
        "    net[\"conv1_eeg\"] = keras.layers.Conv2D(32, (1,2), strides=(1, 1), activation=\"relu\")(net[\"eeg_in\"])\n",
        "    net[\"conv2_eeg\"] = keras.layers.Conv2D(64, (1, 2), strides=(1,1), activation=\"relu\")(net[\"conv1_eeg\"])\n",
        "    net[\"pool_eeg\"] = keras.layers.MaxPooling2D((1, 2))(net[\"conv2_eeg\"])\n",
        "    net[\"out_eeg\"] = network_base.dense_layer(keras.layers.Flatten()(net[\"pool_eeg\"]), units=output_n_eeg, activation='relu')\n",
        "    net[\"fl_in\"]=network_base.input_layer(shape=input_shape_fl)\n",
        "    net[\"conv1_fl\"] = keras.layers.Conv2D(32, (1, 2), strides=(1,1), activation=\"relu\")(net[\"fl_in\"])\n",
        "    net[\"conv2_fl\"] = keras.layers.Conv2D(64, (1, 2), strides=(1,1), activation=\"relu\")(net[\"conv1_fl\"])\n",
        "    net[\"pool_fl\"] = keras.layers.MaxPooling2D((1, 2))(net[\"conv2_fl\"])\n",
        "    net[\"out_fl\"] = network_base.dense_layer(keras.layers.Flatten()(net[\"pool_fl\"]), units=output_n_fl, activation='relu')\n",
        "    net['concat_feat'] = keras.layers.merge.concatenate([net[\"out_eeg\"], net[\"out_fl\"]])\n",
        "    net[\"concat_out\"] = network_base.dense_layer(net[\"concat_feat\"], units=32)\n",
        "    net[\"out\"] = network_base.dense_layer(net[\"concat_out\"], units=output_n)\n",
        "    net[\"sm_out\"] = network_base.softmax(net[\"out\"])\n",
        "\n",
        "    model_with_softmax = Model(inputs=[net['eeg_in'], net['fl_in']], outputs=net['sm_out'])\n",
        "    model_without_softmax = Model(inputs=[net['eeg_in'], net['fl_in']], outputs=net['out'])\n",
        "\n",
        "    \n",
        "    return model_with_softmax, model_without_softmax\n",
        "\n",
        "def build_single_head_net(input_shape=(None, 1, 640, 81*2+32), feature_dim=16, output_n = 3):\n",
        "    net = {}\n",
        "    net[\"in\"] = network_base.input_layer(shape=input_shape)\n",
        "    net[\"conv1\"] = keras.layers.Conv2D(filters=64, kernel_size=(1,2), strides=(1, 1), activation=\"relu\" )(net[\"in\"])\n",
        "    net[\"conv2\"] = keras.layers.Conv2D(filters=128, kernel_size=(1,2), activation=\"relu\")(net[\"conv1\"])\n",
        "    net[\"pool\"] = keras.layers.MaxPooling2D((1, 2))(net[\"conv2\"])\n",
        "    net[\"out_feat\"] = network_base.dense_layer(keras.layers.Flatten()(net[\"pool\"]), units=feature_dim, activation='relu')\n",
        "    net[\"out\"]= network_base.dense_layer(net[\"out_feat\"], units=output_n)\n",
        "    net[\"sm_out\"] = network_base.softmax(net[\"out\"])\n",
        "\n",
        "    model_with_softmax = Model(inputs=net['in'], outputs=net['sm_out'])\n",
        "    model_without_softmax = Model(inputs=net['in'], outputs=net['out'])\n",
        "\n",
        "    return model_with_softmax, model_without_softmax\n",
        "\n",
        "def eeg_net(input_shape_eeg=(None,1, 640, 32),output_n_eeg = 8, output_n = 3):\n",
        "    net = {}\n",
        "    net[\"in\"] = network_base.input_layer(shape=input_shape_eeg)\n",
        "    net[\"conv1_eeg\"] = keras.layers.Conv2D(32, (1,2), strides=(1, 1), activation=\"relu\")(net[\"in\"])\n",
        "    net[\"conv2_eeg\"] = keras.layers.Conv2D(64, (1, 2), strides=(1,1), activation=\"relu\")(net[\"conv1_eeg\"])\n",
        "    net[\"pool_eeg\"] = keras.layers.MaxPooling2D((1, 2))(net[\"conv2_eeg\"])\n",
        "    net[\"out_eeg\"] = network_base.dense_layer(keras.layers.Flatten()(net[\"pool_eeg\"]), units=output_n_eeg, activation='relu')\n",
        "    net[\"out\"]= network_base.dense_layer(net[\"out_eeg\"], units=output_n)\n",
        "    net[\"sm_out\"] = network_base.softmax(net[\"out\"])\n",
        "\n",
        "    model_with_softmax = Model(inputs=net['in'], outputs=net['sm_out'])\n",
        "    model_without_softmax = Model(inputs=net['in'], outputs=net['out'])\n",
        "\n",
        "    return model_with_softmax, model_without_softmax\n",
        "\n",
        "\n",
        "def fl_net( input_shape_fl=(None, 1, 640, 81*2), output_n_fl = 8, output_n = 3):\n",
        "    net = {}\n",
        "    net[\"in\"]=network_base.input_layer(shape=input_shape_fl)\n",
        "    net[\"conv1_fl\"] = keras.layers.Conv2D(32, (1, 2), strides=(1,1), activation=\"relu\")(net[\"in\"])\n",
        "    net[\"conv2_fl\"] = keras.layers.Conv2D(64, (1, 2), strides=(1,1), activation=\"relu\")(net[\"conv1_fl\"])\n",
        "    net[\"pool_fl\"] = keras.layers.MaxPooling2D((1, 2))(net[\"conv2_fl\"])\n",
        "    net[\"out_fl\"] = network_base.dense_layer(keras.layers.Flatten()(net[\"pool_fl\"]), units=output_n_fl, activation='relu')\n",
        "    net[\"out\"]= network_base.dense_layer(net[\"out_fl\"], units=output_n)\n",
        "    net[\"sm_out\"] = network_base.softmax(net[\"out\"])\n",
        "\n",
        "    model_with_softmax = Model(inputs=net['in'], outputs=net['sm_out'])\n",
        "    model_without_softmax = Model(inputs=net['in'], outputs=net['out'])\n",
        "\n",
        "    return model_with_softmax, model_without_softmax\n",
        "  \n",
        "def pretrained(eeg_model, fl_model , input_shape_eeg = (None, 1, 640, 32), input_shape_fl= (None, 1, 640, 162)):\n",
        "    net = {}\n",
        "    for layer in eeg_model.layers[:-4]:\n",
        "      layer.trainable = False\n",
        "    for layer in fl_model.layers[:-4]:\n",
        "      layer.trainable = False\n",
        "    net['eeg_features'] = eeg_model.layers[-3].output\n",
        "    net['fl_features'] = fl_model.layers[-3].output\n",
        "    net['concat_feature']=keras.layers.merge.concatenate([net['eeg_features'], net['fl_features']])\n",
        "    net['out1'] = network_base.dense_layer(net['concat_feature'], units=32)\n",
        "    net['out'] = network_base.dense_layer(net['out1'], units =3)\n",
        "                                          \n",
        "    net[\"sm_out\"] = network_base.softmax(net[\"out\"])\n",
        "    model_with_softmax = Model(inputs=[eeg_model.input, fl_model.input], outputs=net['sm_out'])\n",
        "\n",
        "    return model_with_softmax\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1RGJNaU8Z0k3",
        "outputId": "b727f1cb-1a5b-4fb6-8402-1c67a33d76c3"
      },
      "source": [
        "## Single eeg or fl models\n",
        "import random as rn\n",
        "import tensorflow as tf\n",
        "sd = 1 # Here sd means seed.\n",
        "np.random.seed(sd)\n",
        "rn.seed(sd)\n",
        "os.environ['PYTHONHASHSEED']=str(sd)\n",
        "\n",
        "from keras import backend as K\n",
        "config = tf.ConfigProto(intra_op_parallelism_threads=1,inter_op_parallelism_threads=1)\n",
        "tf.set_random_seed(sd)\n",
        "sess = tf.Session(graph=tf.get_default_graph(), config=config)\n",
        "K.set_session(sess)\n",
        "## Load data\n",
        "dataset=DEAP(subject=16, upsample = True )#\n",
        "train_indices, valid_indices=dataset.train_valid_split()\n",
        "train_X_eeg = dataset[train_indices]['eeg']\n",
        "train_X_eeg = np.expand_dims(train_X_eeg, axis=1)\n",
        "train_X_fl = dataset[train_indices]['face']\n",
        "train_X_fl = np.expand_dims(train_X_fl, axis=1)\n",
        "train_Y = dataset[train_indices]['label_arousal']\n",
        "valid_X_eeg = dataset[valid_indices]['eeg']\n",
        "valid_X_eeg = np.expand_dims(valid_X_eeg, axis=1)\n",
        "valid_X_fl = dataset[valid_indices]['face']\n",
        "valid_X_fl = np.expand_dims(valid_X_fl, axis=1)\n",
        "valid_Y = dataset[valid_indices]['label_arousal']\n",
        "keras.backend.image_data_format == \"channels_first\"\n",
        "\n",
        "input_shape_fl=(1,640,162)\n",
        "input_shape_eeg=(1,640,32)\n",
        "concat_train = np.concatenate((train_X_eeg, train_X_fl), axis = -1)\n",
        "concat_valid = np.concatenate((valid_X_eeg, valid_X_fl), axis = -1)\n",
        "model_with_softmax, model_without_softmax=fl_net()\n",
        "### eeg\n",
        "eeg_model = keras.models.Sequential([\n",
        "    keras.layers.Conv2D(32, (1, 2), strides=(1,1), activation=\"relu\", input_shape=input_shape_eeg),\n",
        "    keras.layers.Conv2D(64, (1, 2), activation=\"relu\"),\n",
        "    keras.layers.MaxPooling2D((1, 2)),\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dense(8, activation=\"relu\"),\n",
        "    keras.layers.Dense(3, activation=\"softmax\"),\n",
        "])\n",
        "###fl\n",
        "fl_model = keras.models.Sequential([\n",
        "    keras.layers.Conv2D(32, (1, 2), strides=(1,1), activation=\"relu\", input_shape=input_shape_fl),\n",
        "    keras.layers.Conv2D(64, (1, 2), activation=\"relu\"),\n",
        "    keras.layers.MaxPooling2D((1, 2)),\n",
        "    keras.layers.Flatten(), \n",
        "    keras.layers.Dense(8, activation=\"relu\"),\n",
        "    keras.layers.Dense(3, activation=\"softmax\"),\n",
        "])\n",
        "\n",
        "opt = keras.optimizers.Adam(lr=0.00005)\n",
        "model_with_softmax.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
        "model_with_softmax.fit(train_X_fl, train_Y, epochs=50, batch_size=32,)\n",
        "scores = model_with_softmax.evaluate(valid_X_fl, valid_Y, batch_size=32)\n",
        "print(\"Scores on test set: loss=%s accuracy=%s\" % tuple(scores))\n",
        "model_without_softmax.set_weights(model_with_softmax.get_weights())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3103: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and now uses scale_factor directly, instead of relying on the computed output size. If you wish to restore the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "384/384 [==============================] - 2s 6ms/step - loss: 0.8821 - accuracy: 0.6615\n",
            "Epoch 2/50\n",
            "384/384 [==============================] - 1s 3ms/step - loss: 0.8651 - accuracy: 0.6615\n",
            "Epoch 3/50\n",
            "384/384 [==============================] - 1s 3ms/step - loss: 0.8638 - accuracy: 0.6615\n",
            "Epoch 4/50\n",
            "384/384 [==============================] - 1s 3ms/step - loss: 0.8439 - accuracy: 0.6615\n",
            "Epoch 5/50\n",
            "384/384 [==============================] - 1s 3ms/step - loss: 0.8451 - accuracy: 0.6615\n",
            "Epoch 6/50\n",
            "384/384 [==============================] - 1s 3ms/step - loss: 0.8485 - accuracy: 0.6615\n",
            "Epoch 7/50\n",
            "384/384 [==============================] - 1s 3ms/step - loss: 0.8294 - accuracy: 0.6615\n",
            "Epoch 8/50\n",
            "384/384 [==============================] - 1s 3ms/step - loss: 0.8347 - accuracy: 0.6615\n",
            "Epoch 9/50\n",
            "384/384 [==============================] - 1s 3ms/step - loss: 0.8221 - accuracy: 0.6615\n",
            "Epoch 10/50\n",
            "384/384 [==============================] - 1s 3ms/step - loss: 0.8216 - accuracy: 0.6615\n",
            "Epoch 11/50\n",
            "384/384 [==============================] - 1s 3ms/step - loss: 0.8200 - accuracy: 0.6615\n",
            "Epoch 12/50\n",
            "384/384 [==============================] - 1s 3ms/step - loss: 0.8110 - accuracy: 0.6615\n",
            "Epoch 13/50\n",
            "384/384 [==============================] - 1s 3ms/step - loss: 0.8045 - accuracy: 0.6615\n",
            "Epoch 14/50\n",
            "384/384 [==============================] - 1s 3ms/step - loss: 0.8017 - accuracy: 0.6615\n",
            "Epoch 15/50\n",
            "384/384 [==============================] - 1s 3ms/step - loss: 0.8067 - accuracy: 0.6615\n",
            "Epoch 16/50\n",
            "384/384 [==============================] - 1s 3ms/step - loss: 0.8005 - accuracy: 0.6615\n",
            "Epoch 17/50\n",
            "384/384 [==============================] - 1s 3ms/step - loss: 0.8023 - accuracy: 0.6615\n",
            "Epoch 18/50\n",
            "384/384 [==============================] - 1s 3ms/step - loss: 0.7954 - accuracy: 0.6615\n",
            "Epoch 19/50\n",
            "384/384 [==============================] - 1s 3ms/step - loss: 0.7853 - accuracy: 0.6615\n",
            "Epoch 20/50\n",
            "384/384 [==============================] - 1s 3ms/step - loss: 0.7937 - accuracy: 0.6615\n",
            "Epoch 21/50\n",
            "384/384 [==============================] - 1s 3ms/step - loss: 0.7980 - accuracy: 0.6641\n",
            "Epoch 22/50\n",
            "384/384 [==============================] - 1s 3ms/step - loss: 0.7776 - accuracy: 0.6615\n",
            "Epoch 23/50\n",
            "384/384 [==============================] - 1s 3ms/step - loss: 0.7740 - accuracy: 0.6615\n",
            "Epoch 24/50\n",
            "384/384 [==============================] - 1s 3ms/step - loss: 0.7758 - accuracy: 0.6641\n",
            "Epoch 25/50\n",
            "384/384 [==============================] - 1s 3ms/step - loss: 0.7697 - accuracy: 0.6615\n",
            "Epoch 26/50\n",
            "384/384 [==============================] - 1s 3ms/step - loss: 0.7690 - accuracy: 0.6615\n",
            "Epoch 27/50\n",
            "384/384 [==============================] - 1s 3ms/step - loss: 0.7915 - accuracy: 0.6641\n",
            "Epoch 28/50\n",
            "384/384 [==============================] - 1s 3ms/step - loss: 0.7678 - accuracy: 0.6667\n",
            "Epoch 29/50\n",
            "384/384 [==============================] - 1s 3ms/step - loss: 0.7600 - accuracy: 0.6615\n",
            "Epoch 30/50\n",
            "384/384 [==============================] - 1s 3ms/step - loss: 0.7624 - accuracy: 0.6667\n",
            "Epoch 31/50\n",
            "384/384 [==============================] - 1s 3ms/step - loss: 0.7571 - accuracy: 0.6693\n",
            "Epoch 32/50\n",
            "384/384 [==============================] - 1s 3ms/step - loss: 0.7719 - accuracy: 0.6693\n",
            "Epoch 33/50\n",
            "384/384 [==============================] - 1s 3ms/step - loss: 0.7634 - accuracy: 0.6667\n",
            "Epoch 34/50\n",
            "384/384 [==============================] - 1s 3ms/step - loss: 0.7703 - accuracy: 0.6667\n",
            "Epoch 35/50\n",
            "384/384 [==============================] - 1s 3ms/step - loss: 0.7577 - accuracy: 0.6667\n",
            "Epoch 36/50\n",
            "384/384 [==============================] - 1s 3ms/step - loss: 0.7511 - accuracy: 0.6745\n",
            "Epoch 37/50\n",
            "384/384 [==============================] - 1s 3ms/step - loss: 0.7623 - accuracy: 0.6510\n",
            "Epoch 38/50\n",
            "384/384 [==============================] - 1s 3ms/step - loss: 0.7363 - accuracy: 0.6719\n",
            "Epoch 39/50\n",
            "384/384 [==============================] - 1s 3ms/step - loss: 0.7434 - accuracy: 0.6693\n",
            "Epoch 40/50\n",
            "384/384 [==============================] - 1s 3ms/step - loss: 0.7472 - accuracy: 0.6615\n",
            "Epoch 41/50\n",
            "384/384 [==============================] - 1s 3ms/step - loss: 0.7385 - accuracy: 0.6771\n",
            "Epoch 42/50\n",
            "384/384 [==============================] - 1s 3ms/step - loss: 0.7324 - accuracy: 0.6615\n",
            "Epoch 43/50\n",
            "384/384 [==============================] - 1s 3ms/step - loss: 0.7354 - accuracy: 0.6693\n",
            "Epoch 44/50\n",
            "384/384 [==============================] - 1s 3ms/step - loss: 0.7276 - accuracy: 0.6719\n",
            "Epoch 45/50\n",
            "384/384 [==============================] - 1s 3ms/step - loss: 0.7281 - accuracy: 0.6719\n",
            "Epoch 46/50\n",
            "384/384 [==============================] - 1s 3ms/step - loss: 0.7258 - accuracy: 0.6771\n",
            "Epoch 47/50\n",
            "384/384 [==============================] - 1s 3ms/step - loss: 0.7195 - accuracy: 0.6693\n",
            "Epoch 48/50\n",
            "384/384 [==============================] - 1s 3ms/step - loss: 0.7235 - accuracy: 0.6745\n",
            "Epoch 49/50\n",
            "384/384 [==============================] - 1s 3ms/step - loss: 0.7126 - accuracy: 0.6719\n",
            "Epoch 50/50\n",
            "384/384 [==============================] - 1s 3ms/step - loss: 0.7165 - accuracy: 0.6693\n",
            "96/96 [==============================] - 1s 10ms/step\n",
            "Scores on test set: loss=0.6306962768236796 accuracy=0.7291666865348816\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n0I6ucxsmeIk"
      },
      "source": [
        "model_with_softmax.save('/content/drive/My Drive/models/fl_softmax_subject_16.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wxROhLs3_yZ2",
        "outputId": "67d8e8b5-d61a-47fb-920b-e18d5f7df357"
      },
      "source": [
        "## EEG+FL models \n",
        "import random as rn\n",
        "import tensorflow as tf\n",
        "sd = 1 # Here sd means seed.\n",
        "np.random.seed(sd)\n",
        "rn.seed(sd)\n",
        "os.environ['PYTHONHASHSEED']=str(sd)\n",
        "\n",
        "from keras import backend as K\n",
        "config = tf.ConfigProto(intra_op_parallelism_threads=1,inter_op_parallelism_threads=1)\n",
        "tf.set_random_seed(sd)\n",
        "sess = tf.Session(graph=tf.get_default_graph(), config=config)\n",
        "K.set_session(sess)\n",
        "## Load data\n",
        "concat = False\n",
        "upsample = True\n",
        "dataset=DEAP(subject=15, upsample = upsample)#\n",
        "train_indices, valid_indices=dataset.train_valid_split()\n",
        "train_X_eeg = dataset[train_indices]['eeg']\n",
        "train_X_eeg = np.expand_dims(train_X_eeg, axis=1)\n",
        "train_X_fl = dataset[train_indices]['face']\n",
        "train_X_fl = np.expand_dims(train_X_fl, axis=1)\n",
        "train_Y = dataset[train_indices]['label_arousal']\n",
        "valid_X_eeg = dataset[valid_indices]['eeg']\n",
        "valid_X_eeg = np.expand_dims(valid_X_eeg, axis=1)\n",
        "valid_X_fl = dataset[valid_indices]['face']\n",
        "valid_X_fl = np.expand_dims(valid_X_fl, axis=1)\n",
        "valid_Y = dataset[valid_indices]['label_arousal']\n",
        "keras.backend.image_data_format == \"channels_first\"\n",
        "\n",
        "if concat:\n",
        "  concat_train = np.concatenate((train_X_eeg, train_X_fl), axis = -1)\n",
        "  concat_valid = np.concatenate((valid_X_eeg, valid_X_fl), axis = -1)\n",
        "  model_with_softmax, model_without_softmax=build_single_head_net()\n",
        "  opt = keras.optimizers.Adam(lr=0.00005)\n",
        "  model_with_softmax.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
        "  model_with_softmax.fit(concat_train, train_Y, epochs=50, batch_size=32,)\n",
        "  scores = model_with_softmax.evaluate(concat_valid, valid_Y, batch_size=32)\n",
        "  print(\"Scores on test set: loss=%s accuracy=%s\" % tuple(scores))\n",
        "  model_without_softmax.set_weights(model_with_softmax.get_weights())\n",
        "\n",
        "if not concat:\n",
        "  opt = keras.optimizers.Adam(lr=0.00005)\n",
        "  model_with_softmax, model_without_softmax=build_two_heads_net(input_shape_fl=(None, 1, 640, 81*2))\n",
        "  model_with_softmax.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
        "  model_with_softmax.fit([train_X_eeg, train_X_fl], train_Y, epochs=50, batch_size=32,)\n",
        "  scores = model_with_softmax.evaluate([valid_X_eeg, valid_X_fl], valid_Y, batch_size=32)\n",
        "  print(\"Scores on test set: loss=%s accuracy=%s\" % tuple(scores))\n",
        "  model_without_softmax.set_weights(model_with_softmax.get_weights())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3103: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and now uses scale_factor directly, instead of relying on the computed output size. If you wish to restore the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "384/384 [==============================] - 3s 9ms/step - loss: 1.0053 - accuracy: 0.5807\n",
            "Epoch 2/50\n",
            "384/384 [==============================] - 2s 5ms/step - loss: 0.8875 - accuracy: 0.6458\n",
            "Epoch 3/50\n",
            "384/384 [==============================] - 2s 5ms/step - loss: 0.8631 - accuracy: 0.6484\n",
            "Epoch 4/50\n",
            "384/384 [==============================] - 2s 5ms/step - loss: 0.8356 - accuracy: 0.6458\n",
            "Epoch 5/50\n",
            "384/384 [==============================] - 2s 5ms/step - loss: 0.8091 - accuracy: 0.6484\n",
            "Epoch 6/50\n",
            "384/384 [==============================] - 2s 5ms/step - loss: 0.7783 - accuracy: 0.6562\n",
            "Epoch 7/50\n",
            "384/384 [==============================] - 2s 5ms/step - loss: 0.7476 - accuracy: 0.6589\n",
            "Epoch 8/50\n",
            "384/384 [==============================] - 2s 5ms/step - loss: 0.7194 - accuracy: 0.6849\n",
            "Epoch 9/50\n",
            "384/384 [==============================] - 2s 5ms/step - loss: 0.6945 - accuracy: 0.6875\n",
            "Epoch 10/50\n",
            "384/384 [==============================] - 2s 5ms/step - loss: 0.6669 - accuracy: 0.6953\n",
            "Epoch 11/50\n",
            "384/384 [==============================] - 2s 5ms/step - loss: 0.6342 - accuracy: 0.7161\n",
            "Epoch 12/50\n",
            "384/384 [==============================] - 2s 5ms/step - loss: 0.6095 - accuracy: 0.7578\n",
            "Epoch 13/50\n",
            "384/384 [==============================] - 2s 5ms/step - loss: 0.5907 - accuracy: 0.7500\n",
            "Epoch 14/50\n",
            "384/384 [==============================] - 2s 5ms/step - loss: 0.5669 - accuracy: 0.7526\n",
            "Epoch 15/50\n",
            "384/384 [==============================] - 2s 5ms/step - loss: 0.5354 - accuracy: 0.7891\n",
            "Epoch 16/50\n",
            "384/384 [==============================] - 2s 5ms/step - loss: 0.5125 - accuracy: 0.7969\n",
            "Epoch 17/50\n",
            "384/384 [==============================] - 2s 5ms/step - loss: 0.4864 - accuracy: 0.8177\n",
            "Epoch 18/50\n",
            "384/384 [==============================] - 2s 5ms/step - loss: 0.4684 - accuracy: 0.8490\n",
            "Epoch 19/50\n",
            "384/384 [==============================] - 2s 5ms/step - loss: 0.4373 - accuracy: 0.8542\n",
            "Epoch 20/50\n",
            "384/384 [==============================] - 2s 5ms/step - loss: 0.4129 - accuracy: 0.8724\n",
            "Epoch 21/50\n",
            "384/384 [==============================] - 2s 5ms/step - loss: 0.4069 - accuracy: 0.8776\n",
            "Epoch 22/50\n",
            "384/384 [==============================] - 2s 5ms/step - loss: 0.3868 - accuracy: 0.8672\n",
            "Epoch 23/50\n",
            "384/384 [==============================] - 2s 5ms/step - loss: 0.3542 - accuracy: 0.9036\n",
            "Epoch 24/50\n",
            "384/384 [==============================] - 2s 5ms/step - loss: 0.3362 - accuracy: 0.8828\n",
            "Epoch 25/50\n",
            "384/384 [==============================] - 2s 5ms/step - loss: 0.3224 - accuracy: 0.9219\n",
            "Epoch 26/50\n",
            "384/384 [==============================] - 2s 5ms/step - loss: 0.2974 - accuracy: 0.9297\n",
            "Epoch 27/50\n",
            "384/384 [==============================] - 2s 5ms/step - loss: 0.2876 - accuracy: 0.9219\n",
            "Epoch 28/50\n",
            "384/384 [==============================] - 2s 5ms/step - loss: 0.2631 - accuracy: 0.9349\n",
            "Epoch 29/50\n",
            "384/384 [==============================] - 2s 5ms/step - loss: 0.2525 - accuracy: 0.9401\n",
            "Epoch 30/50\n",
            "384/384 [==============================] - 2s 5ms/step - loss: 0.2360 - accuracy: 0.9557\n",
            "Epoch 31/50\n",
            "384/384 [==============================] - 2s 5ms/step - loss: 0.2187 - accuracy: 0.9557\n",
            "Epoch 32/50\n",
            "384/384 [==============================] - 2s 5ms/step - loss: 0.2086 - accuracy: 0.9505\n",
            "Epoch 33/50\n",
            "384/384 [==============================] - 2s 5ms/step - loss: 0.2004 - accuracy: 0.9714\n",
            "Epoch 34/50\n",
            "384/384 [==============================] - 2s 5ms/step - loss: 0.1975 - accuracy: 0.9557\n",
            "Epoch 35/50\n",
            "384/384 [==============================] - 2s 5ms/step - loss: 0.1832 - accuracy: 0.9688\n",
            "Epoch 36/50\n",
            "384/384 [==============================] - 2s 5ms/step - loss: 0.1724 - accuracy: 0.9740\n",
            "Epoch 37/50\n",
            "384/384 [==============================] - 2s 5ms/step - loss: 0.1569 - accuracy: 0.9896\n",
            "Epoch 38/50\n",
            "384/384 [==============================] - 2s 5ms/step - loss: 0.1498 - accuracy: 0.9818\n",
            "Epoch 39/50\n",
            "384/384 [==============================] - 2s 5ms/step - loss: 0.1511 - accuracy: 0.9818\n",
            "Epoch 40/50\n",
            "384/384 [==============================] - 2s 5ms/step - loss: 0.1483 - accuracy: 0.9844\n",
            "Epoch 41/50\n",
            "384/384 [==============================] - 2s 5ms/step - loss: 0.1356 - accuracy: 0.9844\n",
            "Epoch 42/50\n",
            "384/384 [==============================] - 2s 5ms/step - loss: 0.1188 - accuracy: 0.9948\n",
            "Epoch 43/50\n",
            "384/384 [==============================] - 2s 5ms/step - loss: 0.1137 - accuracy: 0.9974\n",
            "Epoch 44/50\n",
            "384/384 [==============================] - 2s 5ms/step - loss: 0.1069 - accuracy: 0.9974\n",
            "Epoch 45/50\n",
            "384/384 [==============================] - 2s 5ms/step - loss: 0.1024 - accuracy: 0.9948\n",
            "Epoch 46/50\n",
            "384/384 [==============================] - 2s 5ms/step - loss: 0.0956 - accuracy: 0.9974\n",
            "Epoch 47/50\n",
            "384/384 [==============================] - 2s 5ms/step - loss: 0.0892 - accuracy: 0.9974\n",
            "Epoch 48/50\n",
            "384/384 [==============================] - 2s 5ms/step - loss: 0.0874 - accuracy: 0.9974\n",
            "Epoch 49/50\n",
            "384/384 [==============================] - 2s 5ms/step - loss: 0.0903 - accuracy: 0.9896\n",
            "Epoch 50/50\n",
            "384/384 [==============================] - 2s 5ms/step - loss: 0.0832 - accuracy: 0.9948\n",
            "96/96 [==============================] - 2s 17ms/step\n",
            "Scores on test set: loss=1.5419381062189739 accuracy=0.5625\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WuPAJZAV8-P4",
        "outputId": "497615ff-1ba2-4fb2-e9ed-a238e8416219"
      },
      "source": [
        "## Pre-train + tuning model\n",
        "## Single eeg or fl models\n",
        "import random as rn\n",
        "import tensorflow as tf\n",
        "from keras import backend as K\n",
        "sd = 1 # Here sd means seed.\n",
        "np.random.seed(sd)\n",
        "rn.seed(sd)\n",
        "os.environ['PYTHONHASHSEED']=str(sd)\n",
        "config = tf.ConfigProto(intra_op_parallelism_threads=1,inter_op_parallelism_threads=1)\n",
        "tf.set_random_seed(sd)\n",
        "sess = tf.Session(graph=tf.get_default_graph(), config=config)\n",
        "K.set_session(sess)\n",
        "# IMPORTANT: models have to be loaded AFTER SETTING THE SESSION for keras! \n",
        "# Otherwise, their weights will be unavailable in the threads after the session there has been set\n",
        "\n",
        "eeg=keras.models.load_model('/content/drive/My Drive/models/eeg_softmax_subject_16.h5')\n",
        "fl = keras.models.load_model('/content/drive/My Drive/models/fl_softmax_subject_16.h5')\n",
        "\n",
        "concat = False\n",
        "upsample = True\n",
        "dataset=DEAP(subject=16, upsample = upsample)#\n",
        "train_indices, valid_indices=dataset.train_valid_split()\n",
        "train_X_eeg = dataset[train_indices]['eeg']\n",
        "train_X_eeg = np.expand_dims(train_X_eeg, axis=1)\n",
        "train_X_fl = dataset[train_indices]['face']\n",
        "train_X_fl = np.expand_dims(train_X_fl, axis=1)\n",
        "train_Y = dataset[train_indices]['label_arousal']\n",
        "valid_X_eeg = dataset[valid_indices]['eeg']\n",
        "valid_X_eeg = np.expand_dims(valid_X_eeg, axis=1)\n",
        "valid_X_fl = dataset[valid_indices]['face']\n",
        "valid_X_fl = np.expand_dims(valid_X_fl, axis=1)\n",
        "valid_Y = dataset[valid_indices]['label_arousal']\n",
        "keras.backend.image_data_format == \"channels_first\"\n",
        "\n",
        "def pretrained(eeg_model, fl_model , input_shape_eeg = (None, 1, 640, 32), input_shape_fl= (None, 1, 640, 162)):\n",
        "  net = {}\n",
        "  for layer in eeg_model.layers[:-4]:\n",
        "    layer.trainable = False\n",
        "  for layer in fl_model.layers[:-4]:\n",
        "    layer.trainable = False\n",
        "  net['eeg_features'] = eeg_model.layers[-3].output\n",
        "  net['fl_features'] = fl_model.layers[-3].output\n",
        "  net['concat_feature']=keras.layers.merge.concatenate([net['eeg_features'], net['fl_features']])\n",
        "  net['out1'] = network_base.dense_layer(net['concat_feature'], units=32)\n",
        "  net['out'] = network_base.dense_layer(net['out1'], units =3)\n",
        "                                        \n",
        "  net[\"sm_out\"] = network_base.softmax(net[\"out\"])\n",
        "  model_with_softmax = Model(inputs=[eeg_model.input, fl_model.input], outputs=net['sm_out'])\n",
        "\n",
        "  return model_with_softmax\n",
        "\n",
        "if concat:\n",
        "  concat_train = np.concatenate((train_X_eeg, train_X_fl), axis = -1)\n",
        "  concat_valid = np.concatenate((valid_X_eeg, valid_X_fl), axis = -1)\n",
        "  model_with_softmax, model_without_softmax=build_single_head_net()\n",
        "  opt = keras.optimizers.Adam(lr=0.00005)\n",
        "  model_with_softmax.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
        "  model_with_softmax.fit(concat_train, train_Y, epochs=50, batch_size=32,)\n",
        "  scores = model_with_softmax.evaluate(concat_valid, valid_Y, batch_size=32)\n",
        "  print(\"Scores on test set: loss=%s accuracy=%s\" % tuple(scores))\n",
        "  model_without_softmax.set_weights(model_with_softmax.get_weights())\n",
        "\n",
        "if not concat:\n",
        "  model_with_softmax=pretrained(eeg, fl)\n",
        "  opt = keras.optimizers.Adam(lr=0.00005)\n",
        "  #model_with_softmax, model_without_softmax=build_two_heads_net(input_shape_fl=(None, 1, 640, 81*2))\n",
        "  model_with_softmax.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
        "  model_with_softmax.fit([train_X_eeg, train_X_fl], train_Y, epochs=50, batch_size=32,)\n",
        "  scores = model_with_softmax.evaluate([valid_X_eeg, valid_X_fl], valid_Y, batch_size=32)\n",
        "  print(\"Scores on test set: loss=%s accuracy=%s\" % tuple(scores))\n",
        "  #model_without_softmax.set_weights(model_with_softmax.get_weights())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3103: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and now uses scale_factor directly, instead of relying on the computed output size. If you wish to restore the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "384/384 [==============================] - 1s 3ms/step - loss: 1.1031 - accuracy: 0.4974\n",
            "Epoch 2/50\n",
            "384/384 [==============================] - 1s 2ms/step - loss: 0.8409 - accuracy: 0.6536\n",
            "Epoch 3/50\n",
            "384/384 [==============================] - 1s 2ms/step - loss: 0.8088 - accuracy: 0.6562\n",
            "Epoch 4/50\n",
            "384/384 [==============================] - 1s 2ms/step - loss: 0.7884 - accuracy: 0.6641\n",
            "Epoch 5/50\n",
            "384/384 [==============================] - 1s 2ms/step - loss: 0.7868 - accuracy: 0.6615\n",
            "Epoch 6/50\n",
            "384/384 [==============================] - 1s 2ms/step - loss: 0.7853 - accuracy: 0.6589\n",
            "Epoch 7/50\n",
            "384/384 [==============================] - 1s 2ms/step - loss: 0.7855 - accuracy: 0.6615\n",
            "Epoch 8/50\n",
            "384/384 [==============================] - 1s 2ms/step - loss: 0.7801 - accuracy: 0.6641\n",
            "Epoch 9/50\n",
            "384/384 [==============================] - 1s 2ms/step - loss: 0.7811 - accuracy: 0.6615\n",
            "Epoch 10/50\n",
            "384/384 [==============================] - 1s 2ms/step - loss: 0.7777 - accuracy: 0.6615\n",
            "Epoch 11/50\n",
            "384/384 [==============================] - 1s 2ms/step - loss: 0.7793 - accuracy: 0.6667\n",
            "Epoch 12/50\n",
            "384/384 [==============================] - 1s 2ms/step - loss: 0.7753 - accuracy: 0.6615\n",
            "Epoch 13/50\n",
            "384/384 [==============================] - 1s 2ms/step - loss: 0.7752 - accuracy: 0.6641\n",
            "Epoch 14/50\n",
            "384/384 [==============================] - 1s 2ms/step - loss: 0.7724 - accuracy: 0.6667\n",
            "Epoch 15/50\n",
            "384/384 [==============================] - 1s 2ms/step - loss: 0.7761 - accuracy: 0.6641\n",
            "Epoch 16/50\n",
            "384/384 [==============================] - 1s 2ms/step - loss: 0.7687 - accuracy: 0.6615\n",
            "Epoch 17/50\n",
            "384/384 [==============================] - 1s 2ms/step - loss: 0.7721 - accuracy: 0.6641\n",
            "Epoch 18/50\n",
            "384/384 [==============================] - 1s 2ms/step - loss: 0.7674 - accuracy: 0.6615\n",
            "Epoch 19/50\n",
            "384/384 [==============================] - 1s 2ms/step - loss: 0.7678 - accuracy: 0.6641\n",
            "Epoch 20/50\n",
            "384/384 [==============================] - 1s 2ms/step - loss: 0.7696 - accuracy: 0.6641\n",
            "Epoch 21/50\n",
            "384/384 [==============================] - 1s 2ms/step - loss: 0.7641 - accuracy: 0.6667\n",
            "Epoch 22/50\n",
            "384/384 [==============================] - 1s 2ms/step - loss: 0.7645 - accuracy: 0.6693\n",
            "Epoch 23/50\n",
            "384/384 [==============================] - 1s 2ms/step - loss: 0.7631 - accuracy: 0.6667\n",
            "Epoch 24/50\n",
            "384/384 [==============================] - 1s 2ms/step - loss: 0.7618 - accuracy: 0.6641\n",
            "Epoch 25/50\n",
            "384/384 [==============================] - 1s 2ms/step - loss: 0.7599 - accuracy: 0.6667\n",
            "Epoch 26/50\n",
            "384/384 [==============================] - 1s 2ms/step - loss: 0.7615 - accuracy: 0.6615\n",
            "Epoch 27/50\n",
            "384/384 [==============================] - 1s 2ms/step - loss: 0.7569 - accuracy: 0.6667\n",
            "Epoch 28/50\n",
            "384/384 [==============================] - 1s 2ms/step - loss: 0.7595 - accuracy: 0.6615\n",
            "Epoch 29/50\n",
            "384/384 [==============================] - 1s 2ms/step - loss: 0.7597 - accuracy: 0.6641\n",
            "Epoch 30/50\n",
            "384/384 [==============================] - 1s 2ms/step - loss: 0.7585 - accuracy: 0.6719\n",
            "Epoch 31/50\n",
            "384/384 [==============================] - 1s 2ms/step - loss: 0.7585 - accuracy: 0.6615\n",
            "Epoch 32/50\n",
            "384/384 [==============================] - 1s 2ms/step - loss: 0.7675 - accuracy: 0.6589\n",
            "Epoch 33/50\n",
            "384/384 [==============================] - 1s 2ms/step - loss: 0.7652 - accuracy: 0.6641\n",
            "Epoch 34/50\n",
            "384/384 [==============================] - 1s 2ms/step - loss: 0.7531 - accuracy: 0.6667\n",
            "Epoch 35/50\n",
            "384/384 [==============================] - 1s 2ms/step - loss: 0.7516 - accuracy: 0.6745\n",
            "Epoch 36/50\n",
            "384/384 [==============================] - 1s 2ms/step - loss: 0.7513 - accuracy: 0.6641\n",
            "Epoch 37/50\n",
            "384/384 [==============================] - 1s 2ms/step - loss: 0.7495 - accuracy: 0.6641\n",
            "Epoch 38/50\n",
            "384/384 [==============================] - 1s 2ms/step - loss: 0.7476 - accuracy: 0.6667\n",
            "Epoch 39/50\n",
            "384/384 [==============================] - 1s 2ms/step - loss: 0.7501 - accuracy: 0.6641\n",
            "Epoch 40/50\n",
            "384/384 [==============================] - 1s 2ms/step - loss: 0.7489 - accuracy: 0.6615\n",
            "Epoch 41/50\n",
            "384/384 [==============================] - 1s 2ms/step - loss: 0.7445 - accuracy: 0.6641\n",
            "Epoch 42/50\n",
            "384/384 [==============================] - 1s 2ms/step - loss: 0.7418 - accuracy: 0.6667\n",
            "Epoch 43/50\n",
            "384/384 [==============================] - 1s 2ms/step - loss: 0.7447 - accuracy: 0.6693\n",
            "Epoch 44/50\n",
            "384/384 [==============================] - 1s 2ms/step - loss: 0.7453 - accuracy: 0.6719\n",
            "Epoch 45/50\n",
            "384/384 [==============================] - 1s 2ms/step - loss: 0.7431 - accuracy: 0.6641\n",
            "Epoch 46/50\n",
            "384/384 [==============================] - 1s 2ms/step - loss: 0.7389 - accuracy: 0.6641\n",
            "Epoch 47/50\n",
            "384/384 [==============================] - 1s 2ms/step - loss: 0.7400 - accuracy: 0.6693\n",
            "Epoch 48/50\n",
            "384/384 [==============================] - 1s 2ms/step - loss: 0.7391 - accuracy: 0.6667\n",
            "Epoch 49/50\n",
            "384/384 [==============================] - 1s 2ms/step - loss: 0.7369 - accuracy: 0.6641\n",
            "Epoch 50/50\n",
            "384/384 [==============================] - 1s 2ms/step - loss: 0.7353 - accuracy: 0.6719\n",
            "96/96 [==============================] - 0s 4ms/step\n",
            "Scores on test set: loss=0.581505556901296 accuracy=0.7708333134651184\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VhAAZy3bNe3d"
      },
      "source": [
        "model_with_softmax.save('/content/drive/My Drive/models/pretrain_softmax_subject_15-2.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FNRpiRibXioV"
      },
      "source": [
        "# New section"
      ]
    }
  ]
}